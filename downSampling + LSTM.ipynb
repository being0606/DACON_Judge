{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aebeef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc13fc3c-c1b1-4b77-9ea2-8742c3633345",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./open/train.csv')\n",
    "test = pd.read_csv('./open//test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17e46cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>first_party_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>Phil A. St. Amant</td>\n",
       "      <td>Herman A. Thompson</td>\n",
       "      <td>On June 27, 1962, Phil St. Amant, a candidate ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>Stephen Duncan</td>\n",
       "      <td>Lawrence Owens</td>\n",
       "      <td>Ramon Nelson was riding his bike when he suffe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>Billy Joe Magwood</td>\n",
       "      <td>Tony Patterson, Warden, et al.</td>\n",
       "      <td>An Alabama state court convicted Billy Joe Mag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>Linkletter</td>\n",
       "      <td>Walker</td>\n",
       "      <td>Victor Linkletter was convicted in state court...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>William Earl Fikes</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>On April 24, 1953 in Selma, Alabama, an intrud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>TRAIN_2473</td>\n",
       "      <td>HollyFrontier Cheyenne Refining, LLC, et al.</td>\n",
       "      <td>Renewable Fuels Association, et al.</td>\n",
       "      <td>Congress amended the Clean Air Act through the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2474</th>\n",
       "      <td>TRAIN_2474</td>\n",
       "      <td>Grupo Mexicano de Desarrollo, S. A.</td>\n",
       "      <td>Alliance Bond Fund, Inc.</td>\n",
       "      <td>Alliance Bond Fund, Inc., an investment fund, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>TRAIN_2475</td>\n",
       "      <td>Peguero</td>\n",
       "      <td>United States</td>\n",
       "      <td>In 1992, the District Court sentenced Manuel D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>TRAIN_2476</td>\n",
       "      <td>Immigration and Naturalization Service</td>\n",
       "      <td>St. Cyr</td>\n",
       "      <td>On March 8, 1996, Enrico St. Cyr, a lawful per...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>TRAIN_2477</td>\n",
       "      <td>Markman</td>\n",
       "      <td>Westview Instruments, Inc.</td>\n",
       "      <td>Herbert Markman owns the patent to a system th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2478 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                   first_party  \\\n",
       "0     TRAIN_0000                             Phil A. St. Amant   \n",
       "1     TRAIN_0001                                Stephen Duncan   \n",
       "2     TRAIN_0002                             Billy Joe Magwood   \n",
       "3     TRAIN_0003                                    Linkletter   \n",
       "4     TRAIN_0004                            William Earl Fikes   \n",
       "...          ...                                           ...   \n",
       "2473  TRAIN_2473  HollyFrontier Cheyenne Refining, LLC, et al.   \n",
       "2474  TRAIN_2474           Grupo Mexicano de Desarrollo, S. A.   \n",
       "2475  TRAIN_2475                                       Peguero   \n",
       "2476  TRAIN_2476        Immigration and Naturalization Service   \n",
       "2477  TRAIN_2477                                       Markman   \n",
       "\n",
       "                             second_party  \\\n",
       "0                      Herman A. Thompson   \n",
       "1                          Lawrence Owens   \n",
       "2          Tony Patterson, Warden, et al.   \n",
       "3                                  Walker   \n",
       "4                                 Alabama   \n",
       "...                                   ...   \n",
       "2473  Renewable Fuels Association, et al.   \n",
       "2474             Alliance Bond Fund, Inc.   \n",
       "2475                        United States   \n",
       "2476                              St. Cyr   \n",
       "2477           Westview Instruments, Inc.   \n",
       "\n",
       "                                                  facts  first_party_winner  \n",
       "0     On June 27, 1962, Phil St. Amant, a candidate ...                   1  \n",
       "1     Ramon Nelson was riding his bike when he suffe...                   0  \n",
       "2     An Alabama state court convicted Billy Joe Mag...                   1  \n",
       "3     Victor Linkletter was convicted in state court...                   0  \n",
       "4     On April 24, 1953 in Selma, Alabama, an intrud...                   1  \n",
       "...                                                 ...                 ...  \n",
       "2473  Congress amended the Clean Air Act through the...                   1  \n",
       "2474  Alliance Bond Fund, Inc., an investment fund, ...                   1  \n",
       "2475  In 1992, the District Court sentenced Manuel D...                   0  \n",
       "2476  On March 8, 1996, Enrico St. Cyr, a lawful per...                   0  \n",
       "2477  Herbert Markman owns the patent to a system th...                   0  \n",
       "\n",
       "[2478 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6c67ecd",
   "metadata": {},
   "source": [
    "1. target의 분포 : 불균형발견 -> 다운샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1911509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1649\n",
      "0     829\n",
      "Name: first_party_winner, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "target_distribution = train['first_party_winner'].value_counts()\n",
    "print(target_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "327393c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다운샘플링 후 클래스 분포:\n",
      "0    829\n",
      "1    829\n",
      "Name: first_party_winner, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# 다운샘플링 객체 초기화\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# 다운샘플링을 수행할 feature와 target 데이터를 준비합니다.\n",
    "X_train = train.drop('first_party_winner', axis=1)\n",
    "y_train = train['first_party_winner']\n",
    "\n",
    "# 다운샘플링 수행\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "y_train_resampled = pd.DataFrame(y_train_resampled) # 1열짜리 시리즈 -> ㅇ\n",
    "\n",
    "# 다운샘플링된 데이터셋 확인\n",
    "print(\"다운샘플링 후 클래스 분포:\")\n",
    "print(pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fe948ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c70d6e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/being/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/being/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/being/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/being/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "118daee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 함수를 정의합니다.\n",
    "def tokenize_text(text):\n",
    "    tokens = word_tokenize(text)  # 단어 단위로 토큰화\n",
    "    return tokens\n",
    "\n",
    "#-----------전처리 함수를 정의합니다.-----------\n",
    "# 토큰화 이후에 적용할 수 있는 전처리 단계는 다음과 같습니다:\n",
    "# 1. 소문자 변환: 단어를 모두 소문자로 변환하여 대소문자의 구분을 없애거나 일관성을 유지할 수 있습니다.\n",
    "# 2. 특수 문자 제거: 문장 부호, 기호, 특수 문자 등을 제거하여 모델에 불필요한 잡음을 줄일 수 있습니다.\n",
    "# 3. 불용어 제거: 자주 등장하지만 의미를 갖지 않는 불용어(stop words)를 제거하여 모델의 성능을 개선할 수 있습니다.\n",
    "# 4. 정규화: 단어들을 원형으로 변환하거나 어간 추출(stemming) 등을 수행하여 단어의 다양한 형태를 통합할 수 있습니다.\n",
    "#-----------------------------------------\n",
    "def preprocess_text(text):\n",
    "    # 소문자 변환 / 특수 문자 제거\n",
    "    text = text.lower() \n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "    tokens = tokenize_text(text) # 토큰화\n",
    "\n",
    "    # 불용어 제거\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # 정규화\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2815141",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df = X_train_resampled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "296b02cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'facts' 열에 대해 전처리를 수행하여 새로운 DataFrame을 생성합니다.\n",
    "preprocessed_df['facts_preprocessed'] = preprocessed_df['facts'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ec92d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>first_party</th>\n",
       "      <th>second_party</th>\n",
       "      <th>facts</th>\n",
       "      <th>facts_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>Stephen Duncan</td>\n",
       "      <td>Lawrence Owens</td>\n",
       "      <td>Ramon Nelson was riding his bike when he suffe...</td>\n",
       "      <td>[ramon, nelson, riding, bike, suffered, lethal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>Linkletter</td>\n",
       "      <td>Walker</td>\n",
       "      <td>Victor Linkletter was convicted in state court...</td>\n",
       "      <td>[victor, linkletter, convicted, state, court, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0014</td>\n",
       "      <td>James J. Thole, et al.</td>\n",
       "      <td>U.S. Bank, N.A., et al.</td>\n",
       "      <td>Named plaintiff James Thole and others brought...</td>\n",
       "      <td>[named, plaintiff, james, thole, others, broug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0016</td>\n",
       "      <td>Plyler</td>\n",
       "      <td>Doe</td>\n",
       "      <td>A revision to the Texas education laws in 1975...</td>\n",
       "      <td>[revision, texas, education, law, 1975, allowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0021</td>\n",
       "      <td>Bassam Yacoub Salman</td>\n",
       "      <td>United States</td>\n",
       "      <td>Maher Kara joined Citigroup’s healthcare inves...</td>\n",
       "      <td>[maher, kara, joined, citigroup, ’, healthcare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>TRAIN_0788</td>\n",
       "      <td>United States</td>\n",
       "      <td>Arnold Schwinn &amp; Co., Schwinn Cycle Distributo...</td>\n",
       "      <td>The United States brought an antitrust action ...</td>\n",
       "      <td>[united, state, brought, antitrust, action, ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>TRAIN_0350</td>\n",
       "      <td>Vaughan</td>\n",
       "      <td>Atkinson</td>\n",
       "      <td>The general maritime law of the United States ...</td>\n",
       "      <td>[general, maritime, law, united, state, long, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>TRAIN_1628</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Joe Elton Nixon</td>\n",
       "      <td>A Florida court convicted Joe Elton Nixon of m...</td>\n",
       "      <td>[florida, court, convicted, joe, elton, nixon,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>TRAIN_1820</td>\n",
       "      <td>B. C. Foreman et al.</td>\n",
       "      <td>Dallas County, Texas et al.</td>\n",
       "      <td>In 1972, Texas became a covered jurisdiction f...</td>\n",
       "      <td>[1972, texas, became, covered, jurisdiction, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>TRAIN_1974</td>\n",
       "      <td>Blaine Lafler, Warden</td>\n",
       "      <td>Anthony Cooper</td>\n",
       "      <td>Anthony Cooper was convicted of shooting a wom...</td>\n",
       "      <td>[anthony, cooper, convicted, shooting, woman, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1658 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID             first_party  \\\n",
       "0     TRAIN_0001          Stephen Duncan   \n",
       "1     TRAIN_0003              Linkletter   \n",
       "2     TRAIN_0014  James J. Thole, et al.   \n",
       "3     TRAIN_0016                  Plyler   \n",
       "4     TRAIN_0021    Bassam Yacoub Salman   \n",
       "...          ...                     ...   \n",
       "1653  TRAIN_0788           United States   \n",
       "1654  TRAIN_0350                 Vaughan   \n",
       "1655  TRAIN_1628                 Florida   \n",
       "1656  TRAIN_1820    B. C. Foreman et al.   \n",
       "1657  TRAIN_1974   Blaine Lafler, Warden   \n",
       "\n",
       "                                           second_party  \\\n",
       "0                                        Lawrence Owens   \n",
       "1                                                Walker   \n",
       "2                               U.S. Bank, N.A., et al.   \n",
       "3                                                   Doe   \n",
       "4                                         United States   \n",
       "...                                                 ...   \n",
       "1653  Arnold Schwinn & Co., Schwinn Cycle Distributo...   \n",
       "1654                                           Atkinson   \n",
       "1655                                    Joe Elton Nixon   \n",
       "1656                       Dallas County, Texas et al.    \n",
       "1657                                     Anthony Cooper   \n",
       "\n",
       "                                                  facts  \\\n",
       "0     Ramon Nelson was riding his bike when he suffe...   \n",
       "1     Victor Linkletter was convicted in state court...   \n",
       "2     Named plaintiff James Thole and others brought...   \n",
       "3     A revision to the Texas education laws in 1975...   \n",
       "4     Maher Kara joined Citigroup’s healthcare inves...   \n",
       "...                                                 ...   \n",
       "1653  The United States brought an antitrust action ...   \n",
       "1654  The general maritime law of the United States ...   \n",
       "1655  A Florida court convicted Joe Elton Nixon of m...   \n",
       "1656  In 1972, Texas became a covered jurisdiction f...   \n",
       "1657  Anthony Cooper was convicted of shooting a wom...   \n",
       "\n",
       "                                     facts_preprocessed  \n",
       "0     [ramon, nelson, riding, bike, suffered, lethal...  \n",
       "1     [victor, linkletter, convicted, state, court, ...  \n",
       "2     [named, plaintiff, james, thole, others, broug...  \n",
       "3     [revision, texas, education, law, 1975, allowe...  \n",
       "4     [maher, kara, joined, citigroup, ’, healthcare...  \n",
       "...                                                 ...  \n",
       "1653  [united, state, brought, antitrust, action, ar...  \n",
       "1654  [general, maritime, law, united, state, long, ...  \n",
       "1655  [florida, court, convicted, joe, elton, nixon,...  \n",
       "1656  [1972, texas, became, covered, jurisdiction, p...  \n",
       "1657  [anthony, cooper, convicted, shooting, woman, ...  \n",
       "\n",
       "[1658 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "825ca40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1658, 14357)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 'facts' feature의 텍스트 데이터를 문서로 결합합니다.\n",
    "documents = preprocessed_df['facts'].tolist()\n",
    "\n",
    "# TF-IDF 벡터화 객체를 초기화합니다.\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# TF-IDF 벡터화를 수행하여 문서를 벡터로 표현합니다.\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# TF-IDF 벡터화된 결과를 확인합니다.\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71edc816",
   "metadata": {},
   "source": [
    "# 모델 예측"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad36fa8b",
   "metadata": {},
   "source": [
    "파이캐럿 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af91d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d288b1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid value for the target parameter. Column y not found in the data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/being/Desktop/[github] workspace/DACON_Judge/downSampling + LSTM.ipynb 셀 18\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/being/Desktop/%5Bgithub%5D%20workspace/DACON_Judge/downSampling%20%2B%20LSTM.ipynb#Y105sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m y \u001b[39m=\u001b[39m y_train_resampled  \u001b[39m# 타겟 변수\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/being/Desktop/%5Bgithub%5D%20workspace/DACON_Judge/downSampling%20%2B%20LSTM.ipynb#Y105sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# 파이캐럿을 설정합니다.\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/being/Desktop/%5Bgithub%5D%20workspace/DACON_Judge/downSampling%20%2B%20LSTM.ipynb#Y105sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m setup(data\u001b[39m=\u001b[39;49mX, target\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/being/Desktop/%5Bgithub%5D%20workspace/DACON_Judge/downSampling%20%2B%20LSTM.ipynb#Y105sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# 모델 학습 및 비교를 수행합니다.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/being/Desktop/%5Bgithub%5D%20workspace/DACON_Judge/downSampling%20%2B%20LSTM.ipynb#Y105sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m compare_models()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pycaret/classification/functional.py:602\u001b[0m, in \u001b[0;36msetup\u001b[0;34m(data, data_func, target, index, train_size, test_data, ordinal_features, numeric_features, categorical_features, date_features, text_features, ignore_features, keep_features, preprocess, create_date_columns, imputation_type, numeric_imputation, categorical_imputation, iterative_imputation_iters, numeric_iterative_imputer, categorical_iterative_imputer, text_features_method, max_encoding_ohe, encoding_method, rare_to_value, rare_value, polynomial_features, polynomial_degree, low_variance_threshold, group_features, group_names, drop_groups, remove_multicollinearity, multicollinearity_threshold, bin_numeric_features, remove_outliers, outliers_method, outliers_threshold, fix_imbalance, fix_imbalance_method, transformation, transformation_method, normalize, normalize_method, pca, pca_method, pca_components, feature_selection, feature_selection_method, feature_selection_estimator, n_features_to_select, custom_pipeline, custom_pipeline_position, data_split_shuffle, data_split_stratify, fold_strategy, fold, fold_shuffle, fold_groups, n_jobs, use_gpu, html, session_id, system_log, log_experiment, experiment_name, experiment_custom_tags, log_plots, log_profile, log_data, verbose, memory, profile, profile_kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m exp \u001b[39m=\u001b[39m _EXPERIMENT_CLASS()\n\u001b[1;32m    601\u001b[0m set_current_experiment(exp)\n\u001b[0;32m--> 602\u001b[0m \u001b[39mreturn\u001b[39;00m exp\u001b[39m.\u001b[39;49msetup(\n\u001b[1;32m    603\u001b[0m     data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    604\u001b[0m     data_func\u001b[39m=\u001b[39;49mdata_func,\n\u001b[1;32m    605\u001b[0m     target\u001b[39m=\u001b[39;49mtarget,\n\u001b[1;32m    606\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    607\u001b[0m     train_size\u001b[39m=\u001b[39;49mtrain_size,\n\u001b[1;32m    608\u001b[0m     test_data\u001b[39m=\u001b[39;49mtest_data,\n\u001b[1;32m    609\u001b[0m     ordinal_features\u001b[39m=\u001b[39;49mordinal_features,\n\u001b[1;32m    610\u001b[0m     numeric_features\u001b[39m=\u001b[39;49mnumeric_features,\n\u001b[1;32m    611\u001b[0m     categorical_features\u001b[39m=\u001b[39;49mcategorical_features,\n\u001b[1;32m    612\u001b[0m     date_features\u001b[39m=\u001b[39;49mdate_features,\n\u001b[1;32m    613\u001b[0m     text_features\u001b[39m=\u001b[39;49mtext_features,\n\u001b[1;32m    614\u001b[0m     ignore_features\u001b[39m=\u001b[39;49mignore_features,\n\u001b[1;32m    615\u001b[0m     keep_features\u001b[39m=\u001b[39;49mkeep_features,\n\u001b[1;32m    616\u001b[0m     preprocess\u001b[39m=\u001b[39;49mpreprocess,\n\u001b[1;32m    617\u001b[0m     create_date_columns\u001b[39m=\u001b[39;49mcreate_date_columns,\n\u001b[1;32m    618\u001b[0m     imputation_type\u001b[39m=\u001b[39;49mimputation_type,\n\u001b[1;32m    619\u001b[0m     numeric_imputation\u001b[39m=\u001b[39;49mnumeric_imputation,\n\u001b[1;32m    620\u001b[0m     categorical_imputation\u001b[39m=\u001b[39;49mcategorical_imputation,\n\u001b[1;32m    621\u001b[0m     iterative_imputation_iters\u001b[39m=\u001b[39;49miterative_imputation_iters,\n\u001b[1;32m    622\u001b[0m     numeric_iterative_imputer\u001b[39m=\u001b[39;49mnumeric_iterative_imputer,\n\u001b[1;32m    623\u001b[0m     categorical_iterative_imputer\u001b[39m=\u001b[39;49mcategorical_iterative_imputer,\n\u001b[1;32m    624\u001b[0m     text_features_method\u001b[39m=\u001b[39;49mtext_features_method,\n\u001b[1;32m    625\u001b[0m     max_encoding_ohe\u001b[39m=\u001b[39;49mmax_encoding_ohe,\n\u001b[1;32m    626\u001b[0m     encoding_method\u001b[39m=\u001b[39;49mencoding_method,\n\u001b[1;32m    627\u001b[0m     rare_to_value\u001b[39m=\u001b[39;49mrare_to_value,\n\u001b[1;32m    628\u001b[0m     rare_value\u001b[39m=\u001b[39;49mrare_value,\n\u001b[1;32m    629\u001b[0m     polynomial_features\u001b[39m=\u001b[39;49mpolynomial_features,\n\u001b[1;32m    630\u001b[0m     polynomial_degree\u001b[39m=\u001b[39;49mpolynomial_degree,\n\u001b[1;32m    631\u001b[0m     low_variance_threshold\u001b[39m=\u001b[39;49mlow_variance_threshold,\n\u001b[1;32m    632\u001b[0m     group_features\u001b[39m=\u001b[39;49mgroup_features,\n\u001b[1;32m    633\u001b[0m     group_names\u001b[39m=\u001b[39;49mgroup_names,\n\u001b[1;32m    634\u001b[0m     drop_groups\u001b[39m=\u001b[39;49mdrop_groups,\n\u001b[1;32m    635\u001b[0m     remove_multicollinearity\u001b[39m=\u001b[39;49mremove_multicollinearity,\n\u001b[1;32m    636\u001b[0m     multicollinearity_threshold\u001b[39m=\u001b[39;49mmulticollinearity_threshold,\n\u001b[1;32m    637\u001b[0m     bin_numeric_features\u001b[39m=\u001b[39;49mbin_numeric_features,\n\u001b[1;32m    638\u001b[0m     remove_outliers\u001b[39m=\u001b[39;49mremove_outliers,\n\u001b[1;32m    639\u001b[0m     outliers_method\u001b[39m=\u001b[39;49moutliers_method,\n\u001b[1;32m    640\u001b[0m     outliers_threshold\u001b[39m=\u001b[39;49moutliers_threshold,\n\u001b[1;32m    641\u001b[0m     fix_imbalance\u001b[39m=\u001b[39;49mfix_imbalance,\n\u001b[1;32m    642\u001b[0m     fix_imbalance_method\u001b[39m=\u001b[39;49mfix_imbalance_method,\n\u001b[1;32m    643\u001b[0m     transformation\u001b[39m=\u001b[39;49mtransformation,\n\u001b[1;32m    644\u001b[0m     transformation_method\u001b[39m=\u001b[39;49mtransformation_method,\n\u001b[1;32m    645\u001b[0m     normalize\u001b[39m=\u001b[39;49mnormalize,\n\u001b[1;32m    646\u001b[0m     normalize_method\u001b[39m=\u001b[39;49mnormalize_method,\n\u001b[1;32m    647\u001b[0m     pca\u001b[39m=\u001b[39;49mpca,\n\u001b[1;32m    648\u001b[0m     pca_method\u001b[39m=\u001b[39;49mpca_method,\n\u001b[1;32m    649\u001b[0m     pca_components\u001b[39m=\u001b[39;49mpca_components,\n\u001b[1;32m    650\u001b[0m     feature_selection\u001b[39m=\u001b[39;49mfeature_selection,\n\u001b[1;32m    651\u001b[0m     feature_selection_method\u001b[39m=\u001b[39;49mfeature_selection_method,\n\u001b[1;32m    652\u001b[0m     feature_selection_estimator\u001b[39m=\u001b[39;49mfeature_selection_estimator,\n\u001b[1;32m    653\u001b[0m     n_features_to_select\u001b[39m=\u001b[39;49mn_features_to_select,\n\u001b[1;32m    654\u001b[0m     custom_pipeline\u001b[39m=\u001b[39;49mcustom_pipeline,\n\u001b[1;32m    655\u001b[0m     custom_pipeline_position\u001b[39m=\u001b[39;49mcustom_pipeline_position,\n\u001b[1;32m    656\u001b[0m     data_split_shuffle\u001b[39m=\u001b[39;49mdata_split_shuffle,\n\u001b[1;32m    657\u001b[0m     data_split_stratify\u001b[39m=\u001b[39;49mdata_split_stratify,\n\u001b[1;32m    658\u001b[0m     fold_strategy\u001b[39m=\u001b[39;49mfold_strategy,\n\u001b[1;32m    659\u001b[0m     fold\u001b[39m=\u001b[39;49mfold,\n\u001b[1;32m    660\u001b[0m     fold_shuffle\u001b[39m=\u001b[39;49mfold_shuffle,\n\u001b[1;32m    661\u001b[0m     fold_groups\u001b[39m=\u001b[39;49mfold_groups,\n\u001b[1;32m    662\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    663\u001b[0m     use_gpu\u001b[39m=\u001b[39;49muse_gpu,\n\u001b[1;32m    664\u001b[0m     html\u001b[39m=\u001b[39;49mhtml,\n\u001b[1;32m    665\u001b[0m     session_id\u001b[39m=\u001b[39;49msession_id,\n\u001b[1;32m    666\u001b[0m     system_log\u001b[39m=\u001b[39;49msystem_log,\n\u001b[1;32m    667\u001b[0m     log_experiment\u001b[39m=\u001b[39;49mlog_experiment,\n\u001b[1;32m    668\u001b[0m     experiment_name\u001b[39m=\u001b[39;49mexperiment_name,\n\u001b[1;32m    669\u001b[0m     experiment_custom_tags\u001b[39m=\u001b[39;49mexperiment_custom_tags,\n\u001b[1;32m    670\u001b[0m     log_plots\u001b[39m=\u001b[39;49mlog_plots,\n\u001b[1;32m    671\u001b[0m     log_profile\u001b[39m=\u001b[39;49mlog_profile,\n\u001b[1;32m    672\u001b[0m     log_data\u001b[39m=\u001b[39;49mlog_data,\n\u001b[1;32m    673\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    674\u001b[0m     memory\u001b[39m=\u001b[39;49mmemory,\n\u001b[1;32m    675\u001b[0m     profile\u001b[39m=\u001b[39;49mprofile,\n\u001b[1;32m    676\u001b[0m     profile_kwargs\u001b[39m=\u001b[39;49mprofile_kwargs,\n\u001b[1;32m    677\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pycaret/classification/oop.py:755\u001b[0m, in \u001b[0;36mClassificationExperiment.setup\u001b[0;34m(self, data, data_func, target, index, train_size, test_data, ordinal_features, numeric_features, categorical_features, date_features, text_features, ignore_features, keep_features, preprocess, create_date_columns, imputation_type, numeric_imputation, categorical_imputation, iterative_imputation_iters, numeric_iterative_imputer, categorical_iterative_imputer, text_features_method, max_encoding_ohe, encoding_method, rare_to_value, rare_value, polynomial_features, polynomial_degree, low_variance_threshold, group_features, group_names, drop_groups, remove_multicollinearity, multicollinearity_threshold, bin_numeric_features, remove_outliers, outliers_method, outliers_threshold, fix_imbalance, fix_imbalance_method, transformation, transformation_method, normalize, normalize_method, pca, pca_method, pca_components, feature_selection, feature_selection_method, feature_selection_estimator, n_features_to_select, custom_pipeline, custom_pipeline_position, data_split_shuffle, data_split_stratify, fold_strategy, fold, fold_shuffle, fold_groups, n_jobs, use_gpu, html, session_id, system_log, log_experiment, experiment_name, experiment_custom_tags, log_plots, log_profile, log_data, engine, verbose, memory, profile, profile_kwargs)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[39mif\u001b[39;00m data_func \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     data \u001b[39m=\u001b[39m data_func()\n\u001b[0;32m--> 755\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_dataset(data, target)\n\u001b[1;32m    756\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_param \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mcolumns[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    757\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m index\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pycaret/internal/preprocess/preprocessor.py:148\u001b[0m, in \u001b[0;36mPreprocessor._prepare_dataset\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(y, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    147\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m X\u001b[39m.\u001b[39mcolumns:\n\u001b[0;32m--> 148\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    149\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mInvalid value for the target parameter. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColumn \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m}\u001b[39;00m\u001b[39m not found in the data.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    153\u001b[0m     X, y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mdrop(y, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), X[y]\n\u001b[1;32m    155\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(y, \u001b[39mint\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid value for the target parameter. Column y not found in the data."
     ]
    }
   ],
   "source": [
    "from pycaret.classification import *\n",
    "\n",
    "# 벡터화된 데이터를 X와 y로 나누어 준비합니다.\n",
    "X = tfidf_matrix.toarray()  # TF-IDF 벡터화된 데이터\n",
    "y = y_train_resampled  # 타겟 변수\n",
    "\n",
    "# 파이캐럿을 설정합니다.\n",
    "setup(data=X, target='y')\n",
    "\n",
    "# 모델 학습 및 비교를 수행합니다.\n",
    "compare_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5be3c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1653    1\n",
       "1654    1\n",
       "1655    1\n",
       "1656    1\n",
       "1657    1\n",
       "Name: first_party_winner, Length: 1658, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f186685",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.14 (NGC 22.12/Python 3.8) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
